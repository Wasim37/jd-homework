user10000469@jupyter-user10000469-2dserver3708:~/notespace/model$ python3 train.py
Reading dataset ../files/train.txt... 43995 pairs.
Reading dataset ../files/dev.txt... 4999 pairs.
14886 pre-trained embeddings loaded.
loading data
initializing optimizer
Epoch 0:  12%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€                                                                                                                              | 1/8 [55:54<6:31:22, 3354.58s/it, Loss=4.86]
validating00%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 55/55 [54:53<00:00, 60.79s/it, Batch=5400, Loss=4.83]
training loss:4.855625686818903 validation loss:4.487559935221305¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5500/5500 [55:54<00:00,  1.83it/s]
Epoch 1:  25%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨„                                                                                                          | 2/8 [1:53:48<5:39:03, 3390.51s/it, Loss=4.24]
validating00%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 55/55 [54:37<00:00, 60.71s/it, Batch=5400, Loss=4.23]
training loss:4.235552038192749 validation loss:4.3588747554100475¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5500/5500 [55:37<00:00,  1.83it/s]
Epoch 2:  38%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨†                                                                                        | 3/8 [2:51:37<4:44:30, 3414.06s/it, Loss=3.96]
validating00%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 55/55 [54:35<00:00, 60.64s/it, Batch=5400, Loss=3.7]
training loss:3.9561317658424375 validation loss:4.359008787152095¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5500/5500 [55:35<00:00,  1.85it/s]
Epoch 3:  50%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€                                                                       | 4/8 [3:49:30<3:48:46, 3431.60s/it, Loss=3.72]
validating00%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 55/55 [54:39<00:00, 60.84s/it, Batch=5400, Loss=3.55]
training loss:3.7183003445972096 validation loss:4.410227659421089¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5500/5500 [55:39<00:00,  1.72it/s]
Epoch 4:  62%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨…                                                     | 5/8 [4:47:21<2:52:10, 3443.38s/it, Loss=3.5]
validating00%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 55/55 [54:38<00:00, 60.99s/it, Batch=5400, Loss=4.1]
training loss:3.503333048213612 validation loss:4.506666246132973¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5500/5500 [55:37<00:00,  1.79it/s]
Epoch 5:  75%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨„                                   | 6/8 [5:45:04<1:54:58, 3449.31s/it, Loss=3.31]
validating00%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 55/55 [54:29<00:00, 60.99s/it, Batch=5400, Loss=3.92]
training loss:3.3143862399187953 validation loss:4.6287741760412855¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5500/5500 [55:30<00:00,  1.77it/s]
Epoch 6:  88%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€                  | 7/8 [6:42:47<57:33, 3453.33s/it, Loss=3.15]
validating00%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 55/55 [54:31<00:00, 60.57s/it, Batch=5400, Loss=3.57]
training loss:3.1496329463178463 validation loss:4.766416646349124¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5500/5500 [55:31<00:00,  1.76it/s]
100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 624/624 [02:12<00:00,  4.73it/s]
Epoch 7:  95%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨ƒ       | 52/55 [51:18<03:00, 60.26s/it, Batch=5100, Loss=3.18]
 93%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨…           | 5109/5500 [51:23<03:48,  1.71it/s]
 93%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨„           | 5110/5500 [51:23<03:38,  1.78it/s]
 93%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨„           | 5111/5500 [51:24<03:50,  1.69it/s]
 93%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨„           | 5112/5500 [51:24<03:49,  1.69it/s]
 93%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨„           | 5113/5500 [51:25<03:57,  1.63it/s]
Epoch 7: 100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 8/8 [7:40:20<00:00, 3453.40s/it, Loss=3.01]
validating00%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 55/55 [54:21<00:00, 60.70s/it, Batch=5400, Loss=3.47]
training loss:3.011511110695926 validation loss:4.90740432150853¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5500/5500 [55:21<00:00,  1.81it/s]
100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 624/624 [02:11<00:00,  4.75it/s]



ser10000469@jupyter-user10000469-2dserver3708:~/notespace/model$ python3 rouge_eval.py
Reading from  ../files/test.txt
Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 1.005 seconds.
Prefix dict has been built succesfully.
Test set contains 1000 samples.
Reading dataset ../files/train.txt... 43995 pairs.
14886 pre-trained embeddings loaded.
Loading model:  ../saved_model/cov_pgn/encoder.pt
25.869041442871094 secs used for  initalize predicter
Building hypotheses.
768.2944447994232 secs used for  building hypotheses
Calculating average rouge scores.
rouge1:  {'f': 0.26167873037384076, 'p': 0.27762046117781797, 'r': 0.25315997733127643}
rouge2:  {'f': 0.04201298429513503, 'p': 0.04447904244649462, 'r': 0.04074665879183275}
rougeL:  {'f': 0.15146645951468887, 'p': 0.1767854207296833, 'r': 0.13636035933308463}



user10000469@jupyter-user10000469-2dserver3708:~/notespace/model$ python3 predict.py
Reading dataset ../files/train.txt... 43995 pairs.
14886 pre-trained embeddings loaded.
Loading model:  ../saved_model/cov_pgn/encoder.pt
25.569502592086792 secs used for  initalize predicter
vocab_size:  20004
source:  ÉÌ³¡ Í¬¿î ÏÄ¼¾ ÐÂ¿î Å®×° Å®Ê¿ Ê±÷Ö ²»¹æÔò Ó¡»¨ Ñ©·Ä µõ´øÈ¹ ´óÐ¡ »¨»Ü ×é Àï ÁÏ : 96% ¾Û±½ ÏËÎ¬ £¬ Ï´µÓ Ëµ £¬ 4% °± ö¤ £¬ ÃæÁÏ ËµÃ÷ £¬ ÉÌÆ· µõÅÆ £¬ Æ´»¨ µõ´øÈ¹ £¬ / ÉÌÆ· Ö¸Êý £¬ ²»¿É ¸ÉÏ´ £¬ 1 Éè¼ÆÊ¦ Ëµ £¬ ÔÚ ÒõÁ¹´¦ Ðü¹Ò ÁÀ¸É £¬ Ä£ÌØ Õ¹Ê¾ / £¬ °æÐÍ Ö¸Êý £¬ µ¯Á¦ Ö¸Êý £¬ ²»¿É Æ¯°× £¬ ÈáÈí Ö¸Êý £¬ ºÏ¸ñÖ¤ £¬ ÎÞµ¯ £¬ ÈáÈí £¬ ÐÞÉí £¬ Ä¦µÇ Éú»î £¬ ±³Ãæ Í¼ £¬ Ï´µÓ Óë Êý £¬ ÊÊÖÐ £¬ ºñ±¡ Ö¸Êý £¬ ¿íËÉ £¬µ¯Á¦ £¬ ÊÖÏ´ £¬ ÉÔºñ £¬ ±¡¿î £¬ ÕýÃæÍ¼ £¬ ²úµØ : ½­ËÕ ÄÏÍ¨ £¬ Æ«Ó² £¬ ÖÊÁ¿ µÈ¼¶ : ºÏ¸ñÆ· £¬ ÐÍ 155 / 80A £¬ ¼ìÑéÔ± : ¸ö £¬ ³É·Ö £¬ ²úÆ·Ãû³Æ : Å® Á¬ÒÂÈ¹×éºÏÐÎÊ½ µ¥¼þ ÒÂÃÅ½ó Ì×Í· ÐäÐÍ ³£¹æÐä ÃæÁÏ ÆäËü ÁìÐÍ ÆäËü Í¼°¸ Ö²Îï»¨»Ü ¿îÊ½ µõ´øÈ¹ ÊÊÓÃÄêÁä 25-29ÖÜËê ÉÏÊÐÊ±¼ä 2019ÄêÏÄ¼¾ ÑüÐÍ ×ÔÈ»Ñü Ðä³¤ ÎÞÐä ²ÄÖÊ ¾Ûõ¥ÏËÎ¬ Á÷ÐÐÔªËØ Ó¡»¨ ·ç¸ñ ¸´¹Å·ç ÀªÐÎ HÐÍ È¹ÐÍ ²»¹æÔò È¹³¤ ÖÐ³¤È¹

0.09022641181945801 secs used for  doing prediction
greedy:  Ñ©·Ä ÃæÁÏ £¬ Çá±¡ Æ®ÒÝ £¬ ²»¹æÔò È¹°Ú £¬ Æ®ÒÝ Áé¶¯ £¬ ²»¹æÔò È¹°Ú £¬ Æ®ÒÝ Áé¶¯ £¬ Æ®ÒÝ Áé¶¯ ¡£

0.7091193199157715 secs used for  doing prediction
beam:  Ñ©·Ä ÃæÁÏ £¬ ÖÊµØ Çá±¡ £¬ ´©×Å ÊæÊÊ £¬ ¾ßÓÐ Á¼ºÃ µÄ ´¹ ×¹¸Ð £¬ ´©×Å ÊæÊÊ ²» ÃÆÈÈ ¡£ ²»¹æÔò µÄ È¹°Ú Éè¼Æ £¬ ÐÐ×ß ¼ä Áé¶¯ Æ®ÒÝ £¬ ÐÐ×ß ¼ä ¾¡ÏÔ Áé¶¯ Æ®ÒÝ ÃÀ¸Ð ¡£

ref:  Õâ ¿î µõ´øÈ¹ ÈÃÄãÔÚ ÈËÈº ÖÐ ³ÉÎª Ò»µÀ ö¦Àö µÄ ·ç¾°Ïß £¬ Æ´½Ó »¨ÎÆ ¸öÐÔ ¶ÀÌØ £¬ ²»¹æÔò ÏÂ°Ú ´© ³ö ÊôÓÚ Äã µÄ Î¶µÀ ¡£ ÊÕÑü µÄ ÑüÉí £¬ ÏÔÊÝ ÏÔ¸ß £¬ ÈÃ Äã ¾¡Çé Õ¹ÏÖ ÂüÃî µÄ Éí×Ë £¬ ÐÐ×ß ¼ä É¢·¢ ×Å Å®ÐÔ µÄ ÷ÈÁ¦ ¡£


user10000469@jupyter-user10000469-2dserver3708:~/notespace/model$ python3 predict.py
Reading dataset ../files/train.txt... 43995 pairs.
14886 pre-trained embeddings loaded.
Loading model:  ../saved_model/cov_pgn/encoder.pt
25.435414791107178 secs used for  initalize predicter
vocab_size:  20004
source:  ±ëÂí ¶ùÍ¯ Ì×Í· ÎÀÒÂ ÄÐÍ¯ Ð¡Í¯ ´óÍ¯ ÊæÊÊ ÍâÌ× Çï¼¾ ÐÂ¿î º«ÉÌÑÔ ÀîÏÖ Í¬¿î ºÚÉ« ½¨Òé Éí¸ß ÐÝÏÐ ×ÔÔÚ µÄ ´©ÒÂ ·ç·¶ £¬ ¸ø Íâ³ö ´øÀ´ ¸ü ¶à Å¯Òâ £¬ Ï¸ÃÜ ·ìÖÆ ¹¤ÒÕ £¬ P É½´¨ £¬ ¼ò½à ´óÆø £¬ ´òÆÆ µ¥µ÷ £¬ÕëÖ¯ ·¨Ê½ Ã«È¦²¼ £¬ Æ·Ãû : ¶ùÍ¯ £¬ ÑÕÉ« : ºÚÉ« £¬ ³ñ¶Ð ºì £¬ ÃæÁÏ : 68% ÃÞ 32% µÓ ö¤ £¬ ¸üºÃ µØ ¹ü×¡ ÉíÌå ÈÈÁ¿ £¬ µÖµ² Íâ²¿ º®Æø £¬ ±£Å¯ ÊæÊÊ ÃÞ ÄÚµ¨ £¬ ×ßÏß ¾ùÔÈ Á÷³© £¬ ÕÃÏÔ Æ·ÖÊ ¸Ð £¬ ÐÔ±ð : ÄÐ £¬ µ¯Á¦ ÊÕ¿Ú £¬ ·À·ç ±£Å¯°²È«µÈ¼¶ ÆäËü ¹¦ÄÜ ÆäËü ÊÊÓÃ¼¾½Ú ´ºÇï ÊÊÓÃÐÔ±ð ÄÐÅ®Í¨ÓÃ ÊÊÓÃÄêÁä 12ËêÒÔÉÏ ÉÏÊÐÊ±¼ä 2018´º¼¾ ·ç¸ñ ÆäËü ²ÄÖÊ³É·Ö ÆäËü ÃæÁÏ ÆäËü

0.14351105690002441 secs used for  doing prediction
greedy:  ÎÀÒÂ ²ÉÓÃ ÓÅÖÊ ÃæÁÏ £¬ ÊÖ¸Ð ÈáÈí £¬ ¾ßÓÐ Á¼ºÃ µÄ Ç×·ôÐÔ £¬ Îª Äã ´øÀ´ ÊæÊÊ µÄ ´©×Å ÌåÑé ¡£ ¾«ÖÂ µÄ ³µ ·ìÏß £¬ ÕÃÏÔ ³ö Æ·ÅÆ µÄ ÖÊ¸Ð ¡£

0.526902437210083 secs used for  doing prediction
beam:  Ì×Í· ¿îÊ½ £¬ ÊÊºÏ ¶àÖÖ ³¡¾° ´©×Å £¬ ²ÉÓÃ ÓÅÖÊ µÄ ÃæÁÏ £¬ ÊÖ¸Ð ÊæÊÊ Ï¸Äå £¬ ¾ßÓÐ Á¼ºÃ µÄ Ç×·ôÐÔ £¬ Îª Äã ´øÀ´ ÊæÊÊ µÄ ´©×Å ÌåÑé ¡£

ref:  ÕâÊÇ Ò»¿î ±ëÂí µÄ Ô²Áì Ì×Í· ÎÀÒÂ £¬ ´¿É« µÄ É«µ÷ £¬ ÐØ¿Ú ´¦ ´îÅä ÓÐ logo Ó¡»¨ £¬ ¼òÔ¼ Ê±ÉÐ ¡£ ·À·ç µÄ Ðä¿Ú £¬ ËÉ½ô ÊÊÖÐ £¬ ÈÃ º¢×Ó ´©×Å ÎÞ Êø¸¿ ¸Ð £¬ Íâ³ö ¸ü ÊæÊÊ ¡£


user10000469@jupyter-user10000469-2dserver3708:~/notespace/model$ python3 predict.py
Reading dataset ../files/train.txt... 43995 pairs.
14886 pre-trained embeddings loaded.
Loading model:  ../saved_model/cov_pgn/encoder.pt
25.819286584854126 secs used for  initalize predicter
vocab_size:  20004
source:  ÄÐ×° ¶¼ÊÐ ÌØ¹¤ Á¬Ã± ²å ¼çÐä ÔË¶¯ ÎÀÒÂ ºÚÉ« Ö´ÐÐ ±ê×¼ £¬ ²úµØ : ¹ã¶«Ê¡ ¹ãÖÝÊÐ £¬ Æ·Ãû : ÎÀÒÂ £¬ ( Ö±½Ó ½Ó´¥ Æ¤·ô Àà £¬ °²È« Àà±ð : £¬ ÃæÁÏ : 70% ÃÞ £¬ ³É·Ý : £¬ ÑÕÉ« : »ÒÉ« £¬ ¸ü ÓÐ ÔË¶¯¸Ð £¬ ÃÅ½ó À­Á´ £¬ £¬ 30% ¾Û±½ ÏËÎ¬ £¬ µõÅÆ ½éÉÜ £¬ Áì¿Ú ¡¢ ÏÂ°Ú ¡¢ Ðä¿Ú ²ÉÓÃ ÂÞÎÆ Éè¼Æ £¬ ·À·ç ½ôÖÂ £¬ Ï´Ë® ¿È ±êÊ¶ ×¢ÊÍ £¬ ²»¿É ÓÚ Ï´ºñ¶È ³£¹æ ²ÄÖÊ ÆäËü ÐäÐÍ ³£¹æÐä ÃæÁÏ²ÄÖÊ ÃÞ ÁìÐÍ Ô²Áì Á÷ÐÐÔªËØ ÆäËü ¿îÊ½ ¿ªÉÀ ÉÏÊÐÊ±¼ä 2018Äê´º¼¾ Í¼°¸ ÆäËü °æÐÍ ±ê×¼ÐÍ Ðä³¤ ³¤Ðä »ù´¡·ç¸ñ Çà´ºÁ÷ÐÐ ÊÊÓÃÈËÈº ÇàÄê ÊÊÓÃ³¡¾° ÆäËü ·ç¸ñ Çà´ºÐÝÏÐ

0.15149259567260742 secs used for  doing prediction
greedy:  Õâ¿î ÎÀÒÂ Ñ¡ÓÃ ÓÅÖÊ ÃæÁÏ ÖÆ×÷ £¬ ´¥¸Ð Ï¸Äå Ë³»¬ £¬ ¾ßÓÐ Á¼ºÃ µÄ ÊÊ´© ÐÔ ¡£ ¾«ÖÂ µÄ Á¬Ã± Éè¼Æ £¬ ´©ÍÑ ±ã½Ý £¬ ÌáÉý ´©×Å ÌåÑé ¡£ ¾«ÐÄ µÄ ·ìÏß ¹¤ÒÕ £¬ ×ßÏß Ï¸ÃÜ Á÷³© £¬ ÀÎ¹Ì ÄÍ´© ¡£

0.7358441352844238 secs used for  doing prediction
beam:  Á¬Ã± µÄ Éè¼Æ £¬ ²»½ö ÄÜ ÐÞÊÎ Á³ÐÍ £¬ »¹ ÄÜ Æðµ½ ÐÞÊÎ Á³ÐÍ µÄ ×÷ÓÃ ¡£ ¿íËÉ µÄ °æÐÍ Éè¼Æ £¬ ÄÜ¹» ºÜ ºÃ µÄ ÐÞÊÎ Äã µÄ Éí²Ä £¬ ÈÃ Äã ¿´ÆðÀ´ ¸ü¼Ó µÄ ÓÐ ¾«ÆøÉñ ¡£

ref:  Á¬Ã± Éè¼Æ ÅäºÏ Ïð½î ³éÉþ £¬ Îª Ë§Æø ÎÀÒÂ Æ½Ìí ¶¯¸Ð ÆøÏ¢ £¬ ¿íËÉ Á¢Ìå µÄ °æÐÍ ¼ô²Ã ¼ÓÉÏ ²àÃÅ ½ó ×² É«Ö¯ ´ø ¹¤ÒÕ £¬ Õ¹ÏÖ ×¿¶û ²»Í¬ µÄ Éè¼Æ Æ·Î¶ Óë Çà´º ¸öÐÔ ¡£ ²å ¼çÐä Éè¼Æ ÓÅ»¯ ±Û°ò £¬ ´©×Å ÇáËÉ ¡£µ¯ÐÔ Ðä °Ú ÊÕÊø Áé»î ´îÅä ÀûÂä ¡£
